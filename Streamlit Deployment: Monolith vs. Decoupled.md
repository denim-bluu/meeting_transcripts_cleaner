# **An Architectural Blueprint for Deploying Scalable Agentic Systems with Streamlit and Snowpark Container Services**

## **Section 1: Deconstructing the Streamlit Application Model: A Deep Dive**

To architect a robust and performant multi-user application, it is imperative to first possess a deep and nuanced understanding of the underlying framework's operational model. Streamlit's design, which prioritizes rapid development and ease of use, has specific architectural characteristics that directly influence its behavior under concurrent load. This section dissects these core mechanics to establish a foundational understanding of its capabilities and inherent limitations in a multi-user production environment.

### **1.1. The Client-Server Architecture of Streamlit**

At its core, a Streamlit application operates on a classic client-server model. When an administrator executes the command streamlit run your_app.py, a Python server process is initiated on the host machine. In the context of the proposed deployment, this host will be a container running within a Snowpark Container Services (SPCS) compute pool. This single server process is the computational engine of the application; it is responsible for executing the Python script and performing all associated data processing and logic for every connected user.1

Each user who accesses the application's URL in a web browser establishes a client connection to this central server. The client's role is primarily to render the user interface elements sent by the server and to transmit user interactions (e.g., button clicks, slider adjustments) back to the server. This distinction is of paramount importance: while each user experiences an independent UI in their browser, the computational workload generated by all concurrent users is consolidated and executed by the single, shared Python server process. Any resource-intensive operation initiated by one user will inevitably consume the shared CPU, memory, and I/O resources of that server, directly impacting the responsiveness and performance experienced by all other active users.2

### **1.2. The "Rerun-from-Top" Execution Model and Session State**

Streamlit's execution model is uniquely straightforward: every user interaction triggers a complete rerun of the application's Python script, from the first line to the last.3 This model simplifies the development of interactive applications by eliminating the need for complex callback-driven logic. However, it also means that, by default, each interaction starts from a "blank slate," with all variables being re-initialized on every run.4

To overcome this statelessness and create stateful, multi-step user experiences, Streamlit provides a crucial mechanism: Session State, accessible via the st.session_state object. This object functions as a dictionary-like container that is unique to each individual user session. A "session" is formally defined as a single instance of an app viewed in a browser tab.4 By storing variables within

st.session_state, developers can ensure that data persists across these script reruns for a specific user, allowing for the creation of applications that remember user inputs, selections, and intermediate results.6

This directly addresses the question of native multi-user support. Streamlit _does_ inherently support multiple concurrent users by providing an isolated st.session_state for each one. This ensures that User A's actions and data do not interfere with User B's. However, it is critical to recognize that this isolation applies only to the _state data_ itself, not to the underlying _computational resources_. The server process remains a shared, contended resource.

### **1.3. Concurrency within Streamlit: Threads and Their Limitations**

The Streamlit server architecture internally utilizes threads to manage its operations. A primary "server thread" runs the underlying Tornado web server, which handles HTTP and WebSocket communication. For each script execution triggered by a user's interaction, Streamlit spawns a dedicated "script thread".8 This model allows the server to handle multiple script runs for different users concurrently, up to the limits of the host's resources.

A significant challenge arises when developers attempt to introduce their own custom concurrency models, such as asyncio or Python's threading module, directly into the application script. The provided information indicates that the current backend code already employs these patterns, likely to handle long-running or I/O-bound tasks without blocking the UI for a single user. However, Streamlit does not officially support custom multithreading within application code, and attempting to do so introduces significant technical hurdles.8

The primary issue is the streamlit.errors.NoSessionContext exception. Most Streamlit commands, including those that update the UI (e.g., st.write) or modify session state, are designed to be called from a script thread. These commands rely on a ScriptRunContext object that is attached to the thread to identify which user's session and browser tab they should interact with. Custom threads created by the application code do not possess this context. Consequently, any attempt to call a Streamlit command from a custom thread will fail, as the command has no way of knowing which user's UI to update.8

While the documentation outlines potential workarounds, such as manually propagating the ScriptRunContext to custom threads, these are presented as unofficial patterns, not robust solutions. They come with stern warnings about potential security vulnerabilities and unexpected behavior, especially if the custom thread outlives the parent script thread.8

This leads to a critical conclusion about the current architecture. The very presence of custom async and multithreading logic within the backend module is a powerful indicator of an architectural mismatch. The application's requirements for handling long-running, non-blocking tasks have outgrown the capabilities of a simple, monolithic Streamlit script. The attempt to manage this complexity within the Streamlit process is an anti-pattern. The robust, industry-recognized solution is not to force complex concurrency to work _inside_ Streamlit, but to _relocate_ this logic to an external, purpose-built service designed to handle such tasks efficiently and scalably.9

## **Section 2: The Architectural Crossroads: Monolithic Simplicity vs. Decoupled Scalability**

The decision of how to structure an application for deployment is one of the most critical in its lifecycle. For a multi-user agentic system, this choice directly dictates its performance, scalability, and resilience. The current monolithic approach, while simple to develop, contains inherent architectural flaws that will manifest under concurrent load. A decoupled, microservices-oriented architecture, while requiring more initial setup, provides the only viable path to a robust and scalable system.

### **2.1. Analyzing the Monolithic Pattern (Your Current Approach)**

In the current monolithic architecture, a single container runs the Streamlit server process. The application script, through a simple Python import statement like from backend import module_a, directly invokes the agentic logic. This means that every function call to the backend is executed within the same process, and often the same script thread, that is responsible for rendering the user interface.8

**Advantages:**

- **Development Simplicity:** This pattern is undeniably the fastest way to build a prototype. There is no network communication to manage, no API to design, and no need to run multiple processes during local development.

**Disadvantages (The Critical Issues for Production):**

- **Performance Bottleneck and the "Noisy Neighbor" Problem:** As established, all user requests are processed by the same server process. Consider a scenario with 20 concurrent users. If User A initiates an agentic task that takes 30 seconds to complete, the CPU, memory, and Python Global Interpreter Lock (GIL) contention generated by this task will degrade the performance for all 19 other users. Their own UI interactions will become sluggish and unresponsive, as they are all competing for the same finite resources. This is a classic "noisy neighbor" problem, where one heavy user negatively impacts the experience of all others.
- **Scalability Failure:** The only way to scale a monolithic application is through horizontal scaling—adding more identical instances of the entire container and placing them behind a load balancer. However, this is fundamentally inefficient. If the backend agentic logic is the computational bottleneck (which is highly likely), this scaling strategy forces the deployment of additional, underutilized Streamlit web server components alongside it. It is not possible to scale the compute-intensive backend part of the application independently of the lightweight frontend UI part, leading to wasted resources and increased operational costs.12
- **Lack of Fault Isolation:** The tight coupling of the frontend and backend logic within a single process creates a single point of failure. A critical bug, an unhandled exception, or a memory leak in the backend agentic code will crash the entire server process. This immediately terminates the application for _all_ connected users, not just the one who triggered the faulty operation. A robust system requires fault isolation, where the failure of one component does not cascade and bring down the entire application.12

### **2.2. Championing the Decoupled Pattern (The Recommended Approach)**

The recommended architecture fundamentally redesigns the application into two distinct, communicating services, each running in its own container. This pattern is a well-established best practice for building scalable and resilient web applications.13

Component 1: The Streamlit Frontend Service

This service becomes a pure user interface layer. Its container is extremely lightweight, containing only the code necessary to render the Streamlit UI components. Its sole responsibility is to present information to the user and capture their inputs. When it needs to perform a complex operation or fetch data, it does not execute the logic itself. Instead, it makes a standard HTTP network request to the backend API service.

Component 2: The FastAPI Backend Service

This service is a dedicated, high-performance application designed to handle the heavy computational work. It exposes a well-defined Application Programming Interface (API) that the Streamlit frontend can call. This is where the agentic logic, the Pydantic AI models, and the custom async and multithreaded code should reside.

FastAPI is the ideal technology for this role. It is one of the fastest Python web frameworks available, built from the ground up to support asynchronous operations, which is a perfect match for the existing I/O-bound or long-running tasks in the backend code. Its native integration with Pydantic for data validation provides a seamless and robust way to define the API's request and response structures, leveraging the existing Pydantic AI models.14

**Advantages (Directly Addressing the Monolith's Flaws):**

- **Non-Blocking UI and Superior Perceived Performance:** This is the most significant benefit. When a user clicks a button in the Streamlit app to start an agentic task, the Streamlit service makes a quick, non-blocking API call to the FastAPI backend. It can then _immediately_ update the UI to show a message like st.spinner("Agent is processing your request...") and return control to the user. The heavy 30-second computation happens in the separate backend process, completely decoupled from the UI rendering loop. This transforms the user experience from a "frozen" or "blocking" interface to a responsive, modern web application. It fundamentally separates "perceived performance" (how fast the UI feels) from "task completion time" (how long the backend takes to work), which is crucial for applications with long-running tasks.
- **Independent and Efficient Scalability:** This architecture allows for precise and cost-effective scaling. If user traffic increases and the backend agentic logic becomes the bottleneck, one can scale _only_ the FastAPI service by increasing its container replica count. The lightweight Streamlit frontend service can remain at a lower replica count, ensuring that resources are allocated exactly where they are needed.12
- **Robustness through Fault Isolation:** The services are isolated. If the FastAPI backend experiences a critical error and crashes, the Streamlit frontend remains online. It can be programmed to gracefully handle the backend's unavailability, perhaps by displaying an error message to the user, without crashing the entire user-facing application. This compartmentalization of failure is a hallmark of production-grade systems.12
- **Improved Maintainability and Testability:** The API serves as a formal contract between the frontend and backend. This separation of concerns allows development teams to work on each component independently. The backend can be tested in isolation by simulating API calls, and the frontend can be developed and tested against a mock API server, leading to a more organized and maintainable codebase over the long term.13

### **2.3. Architectural Pattern Comparison**

The following table provides a concise, qualitative comparison of the two architectural patterns across key production metrics.

| Metric                                 | Monolithic Streamlit                                                                                                                       | Decoupled Streamlit + FastAPI                                                                                                       |
| -------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------- |
| **Performance (Perceived)**            | **Poor.** UI responsiveness is directly tied to backend processing time. Long tasks will freeze the UI for the user.                       | **Excellent.** The UI remains responsive by offloading long-running tasks to the backend, providing immediate feedback to the user. |
| **Performance (Throughput)**           | **Fair.** All requests are funneled through a single process, creating contention and limiting the total number of concurrent heavy tasks. | **Excellent.** FastAPI is built for high-performance, asynchronous request handling, enabling significantly higher throughput.      |
| **Scalability**                        | **Poor.** Cannot scale the compute (backend) and UI (frontend) layers independently, leading to inefficient resource allocation.           | **Excellent.** Allows for independent scaling of frontend and backend services to meet demand precisely and cost-effectively.       |
| **Development Complexity (Initial)**   | **Excellent.** The simplest and fastest pattern for initial prototyping and local development.                                             | **Fair.** Requires initial investment in designing an API and managing inter-service communication.                                 |
| **Development Complexity (Long-term)** | **Poor.** Becomes increasingly complex to maintain and debug as the codebase grows and couples more tightly.                               | **Good.** Separation of concerns and a formal API contract lead to a more modular and maintainable system over time.                |
| **Deployment Complexity**              | **Good.** A single container and service definition are straightforward to manage.                                                         | **Fair.** Requires managing two container images and a multi-container service definition.                                          |
| **Maintainability**                    | **Poor.** Changes to the backend can have unintended side effects on the frontend, making updates risky and difficult to test.             | **Excellent.** Clear separation allows for independent updates and testing of components, reducing risk.                            |
| **Fault Isolation**                    | **Poor.** A failure in the backend code crashes the entire application for all users.                                                      | **Excellent.** A backend crash does not take down the frontend, allowing for graceful degradation and improved system resilience.   |
| **Resource Efficiency**                | **Fair.** Inefficient scaling model leads to wasted resources by replicating lightweight UI servers unnecessarily.                         | **Excellent.** Resources can be allocated precisely to the component that needs them, optimizing cost and performance.              |

## **Section 3: A Blueprint for Refactoring to a Decoupled Architecture**

Transitioning from a monolithic structure to a decoupled one is a systematic process of separating concerns and establishing a formal communication protocol (an API) between the new, independent services. This section provides a practical blueprint for this refactoring process.

### **3.1. Designing the FastAPI Backend Service**

The new backend service will become the authoritative engine for all agentic logic. Its design should prioritize performance, clarity, and maintainability.

Project Structure:

A clean, logical project structure is essential for long-term maintainability. Adopting principles from Clean Architecture is highly recommended, where dependencies flow inward from frameworks and drivers to core business logic.18 A suggested structure would be:

backend_service/

├── app/

│   ├── **init**.py

│   ├── main.py             # FastAPI app instantiation, middleware

│   ├── api/

│   │   ├── **init**.py

│   │   └── v1/

│   │       ├── **init**.py

│   │       ├── endpoints.py  # API route definitions

│   │       └── schemas.py    # Pydantic request/response models

│   ├── core/

│   │   ├── **init**.py

│   │   └── agent_logic.py    # Your core agentic functions

│   └── config.py           # Configuration management

├── Dockerfile

└── requirements.txt

Leveraging Pydantic for API Schemas:

A significant advantage of the existing stack is its use of Pydantic. These same models can be repurposed to define the data contracts for the API. In app/api/v1/schemas.py, Pydantic's BaseModel will be used to define the expected structure and data types for API requests and responses. This provides automatic, robust data validation at the edge of the service, preventing invalid data from ever reaching the core logic.15

**Example Schema:**

Python

# In app/api/v1/schemas.py

from pydantic import BaseModel

from typing import List, Dict

class AgentRequest(BaseModel):

user_prompt: str

config_params: Dict

class TaskStatus(BaseModel):

task_id: str

status: str  # e.g., "PENDING", "RUNNING", "SUCCESS", "FAILURE"

message: str

class AgentResult(BaseModel):

task_id: str

output: List[str]

Defining Asynchronous API Endpoints:

For systems with long-running tasks, it is a standard best practice to implement an asynchronous task processing pattern. Instead of making the client wait for the task to complete, the API immediately acknowledges the request and provides a way for the client to check on the task's progress later.20 This requires three key endpoints:

1. **POST /agent/run:** This endpoint initiates the agentic task. It should accept the user's input (validated by the AgentRequest schema), start the background processing (e.g., using FastAPI's BackgroundTasks or a more robust task queue system like Celery or RQ), and immediately return a unique task_id.
2. **GET /agent/status/{task_id}:** This endpoint allows the client to poll for the status of a task. It takes the task_id as a path parameter and returns the current status (e.g., "RUNNING", "SUCCESS") via the TaskStatus schema.
3. **GET /agent/result/{task_id}:** Once the status endpoint reports "SUCCESS," the client calls this endpoint to retrieve the final output of the agentic task, returned in the structure of the AgentResult schema.

This pattern ensures the API remains highly responsive, even when processing tasks that take minutes to complete.

### **3.2. Modifying the Streamlit Frontend Client**

The Streamlit application must be refactored to act as a pure client to the new backend API.

Removing Direct Backend Imports:

The first and most critical step is to remove all from backend import... statements from the Streamlit Python scripts. The frontend must be completely ignorant of the backend's internal implementation details. Its only knowledge of the backend should be the API's URL and the structure of its endpoints.

Making API Calls:

The requests library (for synchronous calls) or httpx (for asynchronous calls) should be used to communicate with the FastAPI service. These calls will replace the previous direct function invocations.

**Example API Interaction in Streamlit:**

Python

import streamlit as st

import requests

import time

BACKEND_URL = "http://backend:8000"  # Using the internal SPCS container name

st.title("Agentic System Interface")

prompt = st.text_area("Enter your prompt:")

if st.button("Run Agent"):

with st.spinner("Submitting task to agent..."):

try:

# 1. Trigger the task

response = requests.post(

f"{BACKEND_URL}/api/v1/agent/run",

json={"user_prompt": prompt, "config_params": {}}

)

response.raise_for_status()

task_info = response.json()

st.session_state['task_id'] = task_info['task_id']

st.success(f"Task submitted successfully! Task ID: {st.session_state['task_id']}")

except requests.exceptions.RequestException as e:

st.error(f"Failed to submit task: {e}")

st.stop()

# 2. Poll for results

if 'task_id' in st.session_state:

task_id = st.session_state['task_id']

with st.spinner(f"Waiting for task {task_id} to complete..."):

while True:

try:

status_response = requests.get(f"{BACKEND_URL}/api/v1/agent/status/{task_id}")

status_response.raise_for_status()

status_info = status_response.json()

if status_info['status'] == 'SUCCESS':

result_response = requests.get(f"{BACKEND_URL}/api/v1/agent/result/{task_id}")

result_response.raise_for_status()

result_data = result_response.json()

st.subheader("Agent Result:")

st.write(result_data['output'])

break

elif status_info['status'] == 'FAILURE':

st.error(f"Task failed: {status_info['message']}")

break

time.sleep(5)  # Poll every 5 seconds

except requests.exceptions.RequestException as e:

st.error(f"Error checking task status: {e}")

break

This example demonstrates the full asynchronous workflow. st.session_state is used to store the task_id across script reruns, and st.spinner provides clear, non-blocking feedback to the user, creating the responsive experience that the monolithic architecture cannot achieve.

### **3.3. Handling Cross-Origin Resource Sharing (CORS)**

When deploying services that communicate via HTTP, browser security policies come into play. A request from one "origin" (e.g., the Streamlit app's domain) to another (the FastAPI app's domain) is considered a cross-origin request and is blocked by default. To allow the Streamlit frontend to communicate with the FastAPI backend, CORS must be explicitly configured on the backend server.

FastAPI makes this straightforward with its CORSMiddleware. In the app/main.py file of the backend service, this middleware must be added, specifying the origins that are allowed to make requests.

**Example CORS Configuration in FastAPI:**

Python

# In backend_service/app/main.py

from fastapi import FastAPI

from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# This should be configured via environment variables for production

# For SPCS, the frontend origin might be the public endpoint URL

origins = [

"http://localhost:8501",  # For local development

"https://your-spcs-public-endpoint-url", # For production

]

app.add_middleware(

CORSMiddleware,

allow_origins=origins,

allow_credentials=True,

allow_methods=["*"],

allow_headers=["*"],

)

#... include your API routers...

This configuration instructs the backend to add the necessary HTTP headers to its responses, signaling to the browser that requests from the Streamlit application's origin are trusted and should be allowed.13 Failure to configure CORS is a common point of failure in decoupled architectures and must be addressed for the application to function correctly.

## **Section 4: Deployment on Snowpark Container Services (SPCS)**

With a robust, decoupled architecture designed, the next step is to translate this design into a concrete deployment on the target platform, Snowpark Container Services. SPCS provides the necessary tools to run both simple and complex multi-container applications directly within the Snowflake ecosystem, keeping compute close to the data.

### **4.1. SPCS Fundamentals: A Quick Primer**

A successful deployment requires a working knowledge of the core SPCS objects that orchestrate containerized applications.21

- **Image Repository:** This is an OCI v2-compliant container image registry hosted within a Snowflake account. Before an application can be deployed, its Docker image(s) must be built and pushed to this repository. It serves as the secure, internal source for all container images that will be run by SPCS.21
- **Compute Pool:** This represents the underlying infrastructure that will execute the containers. A compute pool is a collection of one or more virtual machine (VM) nodes. When creating a compute pool, an administrator specifies the instance family (e.g., CPU-optimized, GPU-enabled) and the minimum and maximum number of nodes for auto-scaling. All services run within the resource boundaries of a specified compute pool.21
- **Service:** A service is the definition of a long-running application within SPCS. It is defined by a YAML specification file that details which container images to run, their configuration (e.g., environment variables, commands), the network endpoints to expose, and the compute pool to run on. For applications like a web UI and API, the "service" is the appropriate object, as SPCS ensures it remains running, automatically restarting any containers that fail.21

### **4.2. Pattern 1: Deploying the Monolith (The "Lift-and-Shift" Approach)**

While not the recommended final architecture, it is instructive to outline the deployment process for the existing monolithic application. This serves as a baseline and a potential intermediate step for migration.

Dockerfile:

A single Dockerfile is created for the entire application. It installs all dependencies for both Streamlit and the backend logic.

Dockerfile

# Use an official Python runtime as a parent image

FROM python:3.10-slim

WORKDIR /app

# Copy and install requirements

COPY requirements.txt.

RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application code

COPY..

# Expose the port Streamlit runs on

EXPOSE 8501

# Run the Streamlit app

CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]

SPCS Service Specification (YAML):

The service specification is simple, defining a single container and exposing a single public endpoint for the Streamlit UI.

YAML

# service_spec_monolith.yaml

spec:

containers:

- name: monolithic-app

image: /<db_name>/<schema_name>/<repo_name>/my_monolithic_app:latest

env:

SNOWFLAKE_WAREHOUSE: <your_warehouse>

endpoints:

- name: streamlit-ui

port: 8501

public: true

This YAML file, along with the pushed Docker image, is used to create the service in SPCS via the CREATE SERVICE SQL command.25

Analysis:

This pattern is straightforward to deploy. However, it carries all the architectural deficiencies discussed in Section 2 directly into the production environment. It will suffer from performance bottlenecks, inefficient scaling, and a lack of fault isolation. It is a "lift-and-shift" of a prototype architecture and is not suitable for a robust, multi-user deployment.

### **4.3. Pattern 2: The Recommended Multi-Container Service**

This pattern directly implements the decoupled architecture on SPCS, leveraging the platform's native support for multi-container applications. This is the robust, scalable, and production-ready approach.

Two Dockerfiles:

Two separate, optimized Dockerfiles are created.

1. **frontend.Dockerfile:** A minimal image for the Streamlit UI. Its requirements.txt should only include streamlit, requests, and other UI-specific libraries.

    Dockerfile

    # frontend.Dockerfile

    FROM python:3.10-slim

    WORKDIR /app

    COPY frontend/requirements.txt.

    RUN pip install --no-cache-dir -r requirements.txt

    COPY frontend/.

    EXPOSE 8501

    CMD ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]

2. **backend.Dockerfile:** An image for the FastAPI service. Its requirements.txt will include fastapi, uvicorn, pydantic, and all libraries required for the agentic logic.

    Dockerfile

    # backend.Dockerfile

    FROM python:3.10-slim

    WORKDIR /app

    COPY backend_service/requirements.txt.

    RUN pip install --no-cache-dir -r requirements.txt

    COPY backend_service/.

    EXPOSE 8000

    CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

SPCS Service Specification (YAML):

This is the key artifact that defines the multi-container service. It lists both containers and defines their relationship.

YAML

# service_spec_decoupled.yaml

spec:

containers:

- name: frontend  # Container for the Streamlit UI

image: /<db_name>/<schema_name>/<repo_name>/my_frontend_app:latest

- name: backend   # Container for the FastAPI API

image: /<db_name>/<schema_name>/<repo_name>/my_backend_app:latest

env:

SNOWFLAKE_WAREHOUSE: <your_warehouse>

# Other backend-specific environment variables

endpoints:

- name: streamlit-ui

port: 8501

public: true # Expose the Streamlit UI to the public internet

Inter-Container Networking:

A crucial feature of SPCS is that all containers defined within a single service are deployed into a shared network namespace. This means they can communicate with each other using their container names as DNS-resolvable hostnames.23

In the specification above:

- The frontend container can make API calls to the backend container by sending requests to the URL http://backend:8000.
- The endpoints section only exposes the frontend container's port 8501 publicly. The backend container's port 8000 is _not_ public. It is only accessible from within the service's private network, specifically by the frontend container. This is a significant security benefit, as the backend API, which contains the core business logic, is shielded from direct external access.22

This multi-container pattern is the canonical way to deploy microservices on SPCS. It aligns perfectly with the recommended decoupled architecture, providing both the logical separation of concerns and the physical isolation of resources.

### **4.4. SPCS Deployment Pattern Analysis**

The choice between these two deployment patterns on SPCS has direct and significant consequences for the application's operational success.

| Metric                               | Pattern 1 (Single-Container Monolith)                                                                                             | Pattern 2 (Multi-Container Decoupled)                                                                                                                                                              |
| ------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Alignment with Performance Goals** | **Poor.** The monolithic process remains the central bottleneck, and deployment on SPCS does not resolve this architectural flaw. | **Excellent.** Isolates the UI rendering from backend computation, ensuring a responsive user experience.                                                                                          |
| **Alignment with Scalability Goals** | **Poor.** Scaling the service means replicating the entire monolith, which is resource-inefficient.                               | **Excellent.** Lays the groundwork for independent scaling. The service can be split into two separate services (frontend, backend) in the future, each with its own scaling rules.                |
| **Resource Isolation**               | **None.** The frontend and backend logic compete for the same CPU and memory resources within a single container.                 | **Good.** While running on the same node(s) in a compute pool, the two containers have separate process spaces, providing a degree of resource isolation.                                          |
| **Configuration Complexity**         | **Low.** A single Dockerfile and a simple service spec are easy to create and manage initially.                                   | **Medium.** Requires management of two Dockerfiles, two images in the repository, and a more complex service specification.                                                                        |
| **Network Security**                 | **Fair.** The entire application process is exposed through a single public endpoint.                                             | **Excellent.** The backend API is not exposed publicly. It can only be accessed by the frontend container within the service's secure, private network, significantly reducing the attack surface. |

## **Section 5: Advanced Operations and Future-Proofing**

Deploying an application is only the first step. Operating it reliably, securely, and cost-effectively requires attention to "day two" operational practices. This section covers essential considerations for running the recommended decoupled application in a production environment on Snowpark Container Services.

### **5.1. Secure Credential Management**

Hardcoding credentials such as database passwords or API keys directly into a Docker image is a severe security vulnerability. SPCS provides robust mechanisms for securely managing and injecting secrets into running containers.

Using Snowflake Secrets:

The recommended practice is to store all sensitive information as Snowflake Secrets. A Secret is a first-class Snowflake object designed to hold confidential data.

Passing Secrets to Containers:

Within the SPCS service specification YAML, these secrets can be passed to the containers either as environment variables or as mounted files. This is accomplished by referencing an External Access Integration that is configured to allow access to the specified secrets.24

**Example (Conceptual):**

YAML

# In service_spec_decoupled.yaml

spec:

containers:

- name: backend

#...

env:

API_KEY: "##SECRET:my_api_key_secret##" # Syntax to inject a secret

#...

Connecting to Snowflake from within SPCS:

For the specific use case of connecting to the Snowflake database from a container running inside SPCS, there is an even more secure and convenient method. SPCS automatically provisions a short-lived (10-minute, auto-refreshing) OAuth token and makes it available to the container at the file path /snowflake/session/token.

Using this token for authentication is the best practice because:

- It eliminates the need to create, manage, or rotate traditional user/password or key-pair credentials.
- The token is only valid for use from within the container's internal network, making it useless if leaked externally.
- It simplifies the connection code, as shown in the Python example below.26

**Example Python Connection using SPCS Token:**

Python

import snowflake.connector

import os

def get_spcs_token():

with open('/snowflake/session/token', 'r') as f:

return f.read()

conn = snowflake.connector.connect(

host=os.getenv('SNOWFLAKE_HOST'), # Special internal hostname

account=os.getenv('SNOWFLAKE_ACCOUNT'),

authenticator='oauth',

token=get_spcs_token(),

warehouse=os.getenv('SNOWFLAKE_WAREHOUSE')

)

### **5.2. Scaling and Resource Management**

The decoupled architecture provides the flexibility to scale resources efficiently as application load changes.

Compute Pool Scaling:

The overall capacity of the infrastructure is controlled at the compute pool level. The MIN_NODES and MAX_NODES parameters in the CREATE COMPUTE POOL command define the boundaries for auto-scaling. If the total resource demand from all running services exceeds the capacity of the current nodes, SPCS will automatically provision new nodes up to the defined maximum. Conversely, it will scale down to the minimum during periods of low load to save costs.23

Service Instance Scaling:

The number of replicas for a specific application is controlled at the service level. The service specification can include min_instances and max_instances properties. Increasing the number of instances will deploy more replicas of the service's containers (both frontend and backend in the multi-container pattern) across the compute pool to handle higher user traffic. For a truly scalable system, the next evolutionary step would be to split the application into two separate SPCS services—one for the frontend and one for the backend. This would allow for independent instance scaling, such that one could run, for example, two frontend instances but ten backend instances if the agentic logic is the primary bottleneck.

### **5.3. Monitoring, Logging, and Debugging**

Effective monitoring and logging are critical for diagnosing issues and understanding application behavior in production.

Accessing Container Logs:

SPCS captures the standard output (stdout) and standard error (stderr) streams from all running containers and routes them to a Snowflake event table. These logs can be queried using SQL, providing a centralized way to inspect application activity and troubleshoot errors. The primary functions for accessing these logs are SYSTEM$GET_SERVICE_LOGS and the table function SPCS_GET_LOGS.21 Querying these logs is the first step in debugging any container that is failing to start or behaving unexpectedly.

Implementing Health Checks:

It is a crucial best practice to include a health check endpoint in any backend service. For the FastAPI service, this would typically be a simple endpoint like GET /health that returns an HTTP 200 OK status if the service is operational.16 While SPCS's native health checking capabilities are evolving, this endpoint is invaluable for several reasons:

- It provides a simple way for operators or automated systems to verify that the backend service is running and responsive.
- If the service is placed behind a load balancer in more advanced configurations, the load balancer can use this endpoint to determine whether to route traffic to a particular container instance.
- It forms the basis of a robust monitoring strategy, where external tools can periodically ping this endpoint to check for service uptime.

By implementing these operational practices, the deployed application can be managed securely, scaled efficiently, and maintained effectively throughout its lifecycle.

## **Conclusions and Recommendations**

The analysis of the Streamlit framework, common architectural patterns, and the capabilities of Snowpark Container Services leads to a clear and definitive set of recommendations for deploying the agentic system for a multi-user environment.

Primary Conclusion: A Decoupled Architecture is Non-Negotiable

The central finding of this report is that the current monolithic architecture is fundamentally unsuited for a multi-user production deployment. Its inherent design, which tightly couples the user interface with backend processing in a single process, will inevitably lead to performance degradation, poor scalability, and a lack of resilience. The presence of custom concurrency logic (async, multithreading) within the existing backend is the most compelling evidence that the application's needs have already surpassed what a monolithic Streamlit model can reliably provide.

Adopting a decoupled architecture, with a lightweight Streamlit service for the frontend and a dedicated, high-performance FastAPI service for the backend, is not merely an improvement but a necessity. This pattern directly addresses the critical requirements of a multi-user system by:

- **Ensuring a Responsive User Experience:** It separates perceived UI performance from backend task completion time, preventing long-running agentic tasks from freezing the application for users.
- **Enabling Efficient Scalability:** It allows the compute-intensive backend to be scaled independently of the lightweight frontend, optimizing resource allocation and cost.
- **Providing Robustness and Fault Isolation:** It contains failures within the backend service, preventing them from crashing the entire user-facing application.

Deployment Recommendation: Embrace the Multi-Container Service Pattern on SPCS

Snowpark Container Services is an ideal platform for this decoupled architecture. Its native support for multi-container services with secure, built-in inter-container networking makes it straightforward to implement the recommended pattern.

**The recommended course of action is as follows:**

1. **Refactor the Application:** Systematically refactor the existing codebase into two distinct services: a Streamlit frontend and a FastAPI backend, following the blueprint outlined in Section 3. Establish a clear, versioned API contract between them using Pydantic schemas. Implement the asynchronous task pattern (run, status, result) to handle long-running agentic processes.
2. **Containerize Services Independently:** Create two separate, optimized Docker images for the frontend and backend services.
3. **Deploy as a Multi-Container Service:** Author a single SPCS service specification YAML that defines both the frontend and backend containers. Configure a public endpoint exclusively for the frontend service, leveraging the secure internal network for communication from the frontend to the backend.
4. **Implement Operational Best Practices:** Utilize Snowflake Secrets for credential management, adopting the SPCS-provided session token for all internal connections to Snowflake. Configure compute pool and service scaling parameters based on expected load. Implement robust logging within the application and a /health endpoint in the FastAPI service to facilitate monitoring and debugging.

By following this architectural and deployment strategy, the resulting system will be performant, scalable, and resilient, providing a stable and responsive experience for its users while leveraging the full power and security of the Snowflake and Snowpark Container Services ecosystem. This approach represents the industry-standard best practice for transitioning a successful prototype into a production-grade application.

### **Works cited**

1. Understanding Streamlit's client-server architecture - Streamlit Docs, accessed on August 15, 2025, https://docs.streamlit.io/develop/concepts/architecture/architecture
2. Understanding Streamlit's client-server architecture - GitHub, accessed on August 15, 2025, https://github.com/streamlit/docs/blob/main/content/develop/concepts/architecture/architecture.md
3. Caching overview - Streamlit Docs, accessed on August 15, 2025, https://docs.streamlit.io/develop/concepts/architecture/caching
4. Add statefulness to apps - Streamlit Docs, accessed on August 15, 2025, https://docs.streamlit.io/develop/concepts/architecture/session-state
5. Advanced concepts of Streamlit, accessed on August 15, 2025, https://docs.streamlit.io/get-started/fundamentals/advanced-concepts
6. Streamlit Session State: Unlocking the Power of Persistent User Data | by why amit | Medium, accessed on August 15, 2025, https://medium.com/@whyamit101/streamlit-session-state-unlocking-the-power-of-persistent-user-data-41d85758bb02
7. Session State - Streamlit Docs, accessed on August 15, 2025, https://docs.streamlit.io/develop/api-reference/caching-and-state/st.session_state
8. Threading in Streamlit - Streamlit Docs, accessed on August 15, 2025, https://docs.streamlit.io/develop/concepts/design/multithreading
9. Optimizing Streamlit for Production ML/DL Gen AI Projects: Enhancing Performance with RQ, accessed on August 15, 2025, https://kshitijkutumbe.medium.com/optimizing-streamlit-for-production-ml-dl-gen-ai-projects-enhancing-performance-with-rq-a140f68014e9
10. How to Run a Background Task in Streamlit and Notify the UI When It Finishes, accessed on August 15, 2025, https://discuss.streamlit.io/t/how-to-run-a-background-task-in-streamlit-and-notify-the-ui-when-it-finishes/95033
11. Scaling Your Streamlit Applications for Better Performance - Reddit, accessed on August 15, 2025, https://www.reddit.com/r/Streamlit/comments/1fdzkpo/scaling_your_streamlit_applications_for_better/
12. Monolithic vs Microservices - Difference Between Software Development Architectures, accessed on August 15, 2025, https://aws.amazon.com/compare/the-difference-between-monolithic-and-microservices-architecture/
13. From Backend To Frontend: Connecting FastAPI And Streamlit ..., accessed on August 15, 2025, https://pybit.es/articles/from-backend-to-frontend-connecting-fastapi-and-streamlit/
14. Streamlit + FastAPI: A New Approach for Rapidly Building and ..., accessed on August 15, 2025, https://www.ifb.me/en/blog/en/ai/streamlitfastapi-kua
15. FastAPI and Streamlit: The Python Duo You Must Know About | Towards Data Science, accessed on August 15, 2025, https://towardsdatascience.com/fastapi-and-streamlit-the-python-duo-you-must-know-about-72825def1243/
16. How to Build an Instant Machine Learning Web Application with Streamlit and FastAPI, accessed on August 15, 2025, https://developer.nvidia.com/blog/how-to-build-an-instant-machine-learning-web-application-with-streamlit-and-fastapi/
17. Streamlit vs FastAPI - Kaggle, accessed on August 15, 2025, https://www.kaggle.com/discussions/questions-and-answers/475580
18. Framework-agnostic backend example using FastAPI. Implements Clean Architecture and CQRS with DDD-inspired patterns, featuring DIP (low coupling), DI (no globals), contextual RBAC, and session-based auth (cookies) - GitHub, accessed on August 15, 2025, https://github.com/ivan-borovets/fastapi-clean-example
19. Streamlit + FastAPI⚡️- The ingredients you need for your next Data Science Recipe | by Afaque Umer - Medium, accessed on August 15, 2025, https://medium.com/codex/streamlit-fastapi-%EF%B8%8F-the-ingredients-you-need-for-your-next-data-science-recipe-ffbeb5f76a92
20. Streamlit + FastAPI : how to dealing with long running process (10min)? - Stack Overflow, accessed on August 15, 2025, https://stackoverflow.com/questions/78370614/streamlit-fastapi-how-to-dealing-with-long-running-process-10min
21. Snowpark Container Services | Snowflake Documentation, accessed on August 15, 2025, https://docs.snowflake.com/en/developer-guide/snowpark-container-services/overview
22. Snowpark Container Services 101: A Complete Overview (2025), accessed on August 15, 2025, https://www.chaosgenius.io/blog/snowpark-container-services/
23. Snowflake Container Mastery: Step-by-Step Deployment of Your ..., accessed on August 15, 2025, https://medium.com/@maseedilyas9848/snowflake-container-mastery-step-by-step-deployment-of-your-multi-container-app-with-snowpark-211682514851
24. Using Snowpark Container Services with DataOps.live, accessed on August 15, 2025, https://docs.dataops.live/docs/snowflake-workloads/snowpark-container-services/
25. sfc-gh-bhess/st_spcs: Simple Streamlit in Snowpark ... - GitHub, accessed on August 15, 2025, https://github.com/sfc-gh-bhess/st_spcs
26. Connecting to Snowflake from a Snowpark Container Services (SPCS) container, accessed on August 15, 2025, https://www.dataops.live/blog/connecting-to-snowflake-from-a-snowpark-container-services-spcs-container
